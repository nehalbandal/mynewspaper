{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Frame the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "- Process of converting free text to structured text is called as Text Vectorization.\n",
    "- This is very common algorithm to transform text into a meaningful representation of numbers which is used to fit machine algorithm for prediction.\n",
    "\n",
    "- Count Vectorizer give number of frequency with respect to index of vocabulary where as tf-idf consider overall documents of weight of words.\n",
    "    \n",
    "\n",
    "### Term Frequency (TF)\n",
    "\n",
    "- The number of times a word appears in a document divded by the total number of words in the document. \n",
    "- Every document has its own term frequency.\n",
    "\n",
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "- The log of the number of documents divided by the number of documents that contain the word w. \n",
    "- Inverse data frequency determines the weight of rare words across all documents in the corpus.\n",
    "\n",
    "\n",
    "- TF-IDF measures the originality of word by comparing number of times word appear in a doc and number of docs where that word appears in.\n",
    "    TF-IDF = TF(t, d) * IDF(t)\n",
    "    where t-> term d -> number of times t appear in doc, d\n",
    "- TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\".\\data\\BBC News Train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xb6be74ee48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Category'].value_counts().plot.bar(ylim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=10, sublinear_tf=True, stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df.Text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1490, 4165)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape  # (num of documents, total unique words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business':\n",
      "  . Most correlated unigrams: growth, bank, shares\n",
      "  . Most correlated bigrams: \n",
      "# 'politics':\n",
      "  . Most correlated unigrams: blair, election, labour\n",
      "  . Most correlated bigrams: \n",
      "# 'tech':\n",
      "  . Most correlated unigrams: technology, software, users\n",
      "  . Most correlated bigrams: \n",
      "# 'entertainment':\n",
      "  . Most correlated unigrams: singer, actor, film\n",
      "  . Most correlated bigrams: \n",
      "# 'sport':\n",
      "  . Most correlated unigrams: match, coach, cup\n",
      "  . Most correlated bigrams: \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "N = 3  # top 3 most correlated categories/words\n",
    "\n",
    "for category in set(df.Category):\n",
    "    features_chi2 = chi2(features, categories == category) \n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}':\".format(category))\n",
    "    print(\"  . Most correlated unigrams: {}\".format(', '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams: {}\".format(', '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# mlb = MultiLabelBinarizer()\n",
    "# categories_enc = mlb.fit_transform(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1192, 4165), (298, 4165), (1192,), (298,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, categories, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, grid_param):\n",
    "    print(\"Obtaining Best Model for {}\".format(model.__class__.__name__))\n",
    "    grid_search = GridSearchCV(model, grid_param, cv=kf, scoring='accuracy', return_train_score=True, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Best Parameters: \", grid_search.best_params_)\n",
    "        \n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_measures(model, store_results=True):\n",
    "    train_acc = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "    test_acc = cross_val_score(model, X_test, y_test, scoring='accuracy', cv=kf, n_jobs=-1)\n",
    "    print(\"Mean Train Accuracy: {}\\nMean Test Accuracy: {}\".format(train_acc.mean()*100, test_acc.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining Best Model for LogisticRegression\n",
      "Best Parameters:  {'C': 10, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_clf = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "logistic_param_grid = [{'C':[0.1, 1, 10], 'penalty':['l1', 'l2']}]\n",
    "best_logistic_clf = grid_search(logistic_clf, logistic_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train Accuracy: 97.06304279033789\n",
      "Mean Test Accuracy: 96.64406779661017\n"
     ]
    }
   ],
   "source": [
    "performance_measures(best_logistic_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining Best Model for RandomForestClassifier\n",
      "Best Parameters:  {'n_estimators': 300}\n",
      "Best Model's F1 Score:  94.63024708196694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(max_features='auto', random_state=42, n_jobs=-1)\n",
    "forest_param_grid = [{'n_estimators':[100, 200, 300], 'max_depth':[6, 8, 12]}]\n",
    "best_forest_clf = grid_search(forest_clf, forest_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test Accuracy: 90.94915254237289\n",
      "Mean Test F1: 0.9036784634721633\n"
     ]
    }
   ],
   "source": [
    "performance_measures(best_forest_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(random_state=42, n_jobs=-1)\n",
    "xgb_param_grid = [{'max_depth':[6, 8, 12],'n_estimators':[50, 100, 300]}]\n",
    "best_xgb_clf = grid_search(xgb_clf, xgb_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_measures(best_xgb_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'business':\n",
      "  . Top unigrams:\n",
      "       . bank\n",
      "       . firm\n",
      "       . shares\n",
      "  . Top bigrams:\n",
      "       . \n",
      "# 'entertainment':\n",
      "  . Top unigrams:\n",
      "       . film\n",
      "       . tv\n",
      "       . singer\n",
      "  . Top bigrams:\n",
      "       . \n",
      "# 'politics':\n",
      "  . Top unigrams:\n",
      "       . labour\n",
      "       . blair\n",
      "       . government\n",
      "  . Top bigrams:\n",
      "       . \n",
      "# 'sport':\n",
      "  . Top unigrams:\n",
      "       . match\n",
      "       . cup\n",
      "       . coach\n",
      "  . Top bigrams:\n",
      "       . \n",
      "# 'tech':\n",
      "  . Top unigrams:\n",
      "       . computer\n",
      "       . software\n",
      "       . users\n",
      "  . Top bigrams:\n",
      "       . \n"
     ]
    }
   ],
   "source": [
    "# According to model which are top correlated unigram and bigrams.\n",
    "\n",
    "N = 3\n",
    "for category_id, Category in enumerate(best_pac_clf.classes_):\n",
    "    indices = np.argsort(best_logistic_clf.coef_[category_id])  \n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 1][:N]\n",
    "    bigrams = [v for v in reversed(feature_names) if len(v.split(' ')) == 2][:N]\n",
    "    print(\"# '{}':\".format(Category))\n",
    "    print(\"  . Top unigrams:\\n       . {}\".format('\\n       . '.join(unigrams)))\n",
    "    print(\"  . Top bigrams:\\n       . {}\".format('\\n       . '.join(bigrams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('text_vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=10, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=True,\n",
       "                                 token_...rn='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('classifier',\n",
       "                 PassiveAggressiveClassifier(C=1, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False,\n",
       "                                             fit_intercept=True, loss='hinge',\n",
       "                                             max_iter=1000, n_iter_no_change=5,\n",
       "                                             n_jobs=-1, random_state=42,\n",
       "                                             shuffle=True, tol=0.001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "final_model = Pipeline([('text_vect', tfidf),\n",
    "                       ('classifier', best_logistic_clf)])\n",
    "\n",
    "final_model.fit(df.Text, df.Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\ml_model\\\\t_news_classifier.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4efe363faae4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_logistic_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'..\\ml_model\\t_news_classifier.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Software\\Anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mNumpyPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\ml_model\\\\t_news_classifier.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(best_logistic_clf, 'news_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
